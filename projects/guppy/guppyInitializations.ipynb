{
 "metadata": {
  "name": "guppyInitializations"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#===============================================================================\n",
      "#  This bar is just here to show the 80 character margin since I can't currently\n",
      "#  see a way to do that in ipython itself.\n",
      "#==============================================================================="
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #  BTL - 2013.07.15\n",
      "    #  This is just while I'm figuring out how to do tests of things in ipython, \n",
      "    #  particularly when they involve creating and moving to directories that \n",
      "    #  may be very different for tzar.\n",
      "    \n",
      "    #  ONCE THINGS ARE FIGURED OUT, ALL USES OF tempDontMakeDirsYet \n",
      "    #  NEED TO BE REMOVED AND THIS LITTLE BLOCK NEEDS TO BE REMOVED.\n",
      "\n",
      "tempDontMakeDirsYet = True\n",
      "print \"\\n\\n\\n====>>>  tempDontMakeDirsYet = \", tempDontMakeDirsYet, \"\\n\\n\\n\"\n",
      "\n",
      "verbose = False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "\n",
        "====>>>  tempDontMakeDirsYet =  True \n",
        "\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#                               guppyInitializations.py\n",
      "\n",
      "#  Initialize global guppy variables and create necessary directories, etc.\n",
      "\n",
      "#  Usage:\n",
      "#      python 'guppyInitializations.py'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  NOTE:\n",
      "#\n",
      "#  Many things in here have an absolute path that looks like this:\n",
      "#\n",
      "#\t\t\t/Users/Bill/D/rdv-framework/lib/maxent\n",
      "#\n",
      "#  This will fail when moved to windows or linux because rdv is not in:\n",
      "#\n",
      "#\t\t\t/Users/Bill/D\n",
      "#\n",
      "#  Is that lead-in for rdv's location available somewhere as a variable\n",
      "#  in the variables list?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Output from log file of a tzar run of the R version to show what values should be produced"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Location of log file this output is taken from:\n",
      "\n",
      "(paths copied from TextWrangler top bar's File Path pulldown)\n",
      "\n",
      "path ========> ~/tzar/outputdata/Guppy/default_runset/114_Scen_1/logging.log\n",
      "\n",
      "full path =====> /Users/Bill/tzar/outputdata/Guppy/default_runset/114_Scen_1/logging.log\n",
      "\n",
      "url =========> file://localhost/Users/Bill/tzar/outputdata/Guppy/default_runset/114_Scen_1/logging.log\n",
      "\n",
      "\n",
      "At svn guppy revision 259, have removed the full output echo that was in the next cell for now because it's quite large and I'm not doing anything with it.  If you need to see it, look at svn version 259 of this file (BTL - 2013.07.24)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#===============================================================================\n",
      "#  This bar is just here to show the 80 character margin since I can't currently\n",
      "#  see a way to do that in ipython itself.\n",
      "#===============================================================================\n",
      "\n",
      "#  History:\n",
      "\n",
      "#  2013.07.24 - BTL\n",
      "#  Had converted to python by doing it all inside an ipython notebook and \n",
      "#  incrementally testing each little bit of code.  Now want to create a \n",
      "#  class for Guppy and turn this initialization code into a method for that \n",
      "#  class.  Unfortunately, ipython cannot execute multiple cells at once \n",
      "#  and if you make a method that spans multiple cells, there will be \n",
      "#  indentation and ipython will get upset about that indentation when it tries \n",
      "#  to run just one cell where the reason for the indentation is not visible \n",
      "#  in that cell.  So, I'm now going to strip this file down to one method or  \n",
      "#  a small number of methods, with each method in its own (possibly very long) \n",
      "#  cell.  Once I have these methods built, I'll go create the Guppy class and \n",
      "#  hang all this off of there.\n",
      "\n",
      "#  2013.07.14 - BTL\n",
      "#  Converted to python.\n",
      "\n",
      "#  2013.04 - BTL\n",
      "#  Split out of guppy.test.maxent.v9.R and later versions of runMaxent.R.\n",
      "\n",
      "#===============================================================================\n",
      "\n",
      "#  NOTE:\n",
      "#\n",
      "#  Many things in here have an absolute path that looks like this:\n",
      "#\n",
      "#\t\t\t/Users/Bill/D/rdv-framework/lib/maxent\n",
      "#\n",
      "#  This will fail when moved to windows or linux because rdv is not in:\n",
      "#\n",
      "#\t\t\t/Users/Bill/D\n",
      "#\n",
      "#  Is that lead-in for rdv's location available somewhere as a variable\n",
      "#  in the variables list?\n",
      "\n",
      "#===============================================================================\n",
      "\n",
      "#  Output from log file of a tzar run of the R version to show what values \n",
      "#  should be produced:\n",
      "#\n",
      "#  Location of log file this output is taken from:\n",
      "#\n",
      "#  (paths copied from TextWrangler top bar's File Path pulldown)\n",
      "#\n",
      "#  path ========> ~/tzar/outputdata/Guppy/default_runset/114_Scen_1/logging.log\n",
      "#\n",
      "#  full path =====> /Users/Bill/tzar/outputdata/Guppy/default_runset/114_Scen_1/logging.log\n",
      "#\n",
      "#  url =========> file://localhost/Users/Bill/tzar/outputdata/Guppy/default_runset/114_Scen_1/logging.log\n",
      "#\n",
      "#  At svn guppy revision 259, have removed the full output echo that was in \n",
      "#  the next cell for now because it's quite large and I'm not doing anything \n",
      "#  with it. \n",
      "#  If you need to see it, look at svn version 259 of guppyInitializations.ipynb.\n",
      "#  (BTL - 2013.07.24).\n",
      "\n",
      "#===============================================================================\n",
      "\n",
      "    #  BTL - 2013.07.15\n",
      "    #  This is just while I'm figuring out how to do tests of things in ipython, \n",
      "    #  particularly when they involve creating and moving to directories that \n",
      "    #  may be very different for tzar.\n",
      "    \n",
      "    #  ONCE THINGS ARE FIGURED OUT, ALL USES OF tempDontMakeDirsYet \n",
      "    #  NEED TO BE REMOVED AND THIS LITTLE BLOCK NEEDS TO BE REMOVED.\n",
      "\n",
      "tempDontMakeDirsYet = True\n",
      "print \"\\n\\n\\n====>>>  tempDontMakeDirsYet = \", tempDontMakeDirsYet, \"\\n\\n\\n\"\n",
      "\n",
      "verbose = False\n",
      "\n",
      "#===============================================================================\n",
      "\n",
      "import os\n",
      "from pprint import pprint\n",
      "import random\n",
      "\n",
      "    #  For testing only?\n",
      "import yaml\n",
      "import pickle\n",
      "\n",
      "#===============================================================================\n",
      "\n",
      "    #  Note that the function below will need its reference to \n",
      "    #  tempDontMakeDirsYet removed once that issue is all straightened out. \n",
      "    #  That variable can just be set to False, but it will be better to wipe \n",
      "    #  it out altogether when things are working right.\n",
      "\n",
      "def createDirIfDoesntExist (dirToMake):\n",
      "\tif tempDontMakeDirsYet:\n",
      "\t\tprint \"\\n====>>>  Would make dir '\" + dirToMake + \"' now.\"\n",
      "\telse:\n",
      "\t\tif not os.path.isdir (dirToMake):\n",
      "\t\t\tos.makedirs (dirToMake)\n",
      "            \n",
      "#===============================================================================\n",
      "\n",
      "class Guppy (object):\n",
      "    \"\"\"Overarching class for everything about managing a Guppy run.\n",
      "    \"\"\"\n",
      "    def __init__ (self, constants=None, variables=None, \\\n",
      "                        qualifiedParams=None, runParams=None):\n",
      "        \n",
      "        self.constants = constants or {}\n",
      "        self.variables = variables or {}\n",
      "        self.qualifiedParams = qualifiedParams or {}\n",
      "        self.runParams = runParams or {}\n",
      "        self.curDir = os.getcwd()\n",
      "        \n",
      "        if (verbose):\n",
      "            print (\"\\n-----------------------------\\n\\nPARAMS AS PASSED IN:\")\n",
      "            self.pprintParamValues()\n",
      "        \n",
      "        self.variables [\"test\"] = \"varTest\"\n",
      "        self.qualifiedParams [\"test\"] = \"qpTest\"\n",
      "        self.runParams [\"test\"] = \"rpTest\"\n",
      "\n",
      "        self.createConstants ()\n",
      "        self.setRandomSeed ()\n",
      "        self.initNumProcessors ()\n",
      "        self.initDirectories ()\n",
      "        \n",
      "    def createConstants (self):\n",
      "\n",
      "            #  How does python sense this for each OS?\n",
      "            #  Should this be in the yaml file or deduced somehow from the OS \n",
      "            #  or ???\n",
      "        self.constants [\"dirSlash\"] = \"/\"\n",
      "        \n",
      "    def setRandomSeed (self):\n",
      "        randomSeed = self.variables ['PAR.random.seed']\n",
      "        print \"\\nrandom.seed = '\" + str(randomSeed) + \"', class (randomSeed) = '\" + randomSeed.__class__.__name__\n",
      "        random.seed (randomSeed)\n",
      "        \n",
      "    def initNumProcessors (self):\n",
      "            #---------------------------------------------------\n",
      "            #  default value for number of processors in the\n",
      "            #  current machine.\n",
      "            #  maxent can use this value to speed up some\n",
      "            #  of its operations by creating more threads.\n",
      "            #  It's not a necessary thing to set for any other\n",
      "            #  reason.\n",
      "            #---------------------------------------------------\n",
      "            \n",
      "        self.PARnumProcessors = self.variables ['PAR.num.processors']\n",
      "        print \"\\nPARnumProcessors =\", self.PARnumProcessors\n",
      "        \n",
      "    def initDirectories (self):\n",
      "        self.startingDir = os.getcwd()\n",
      "        print \"\\nstartingDir = '\" + self.startingDir + \"'\"\n",
      "        \n",
      "        self.pathToRfiles = self.variables ['PAR.pathToRfiles']\n",
      "        print \"\\npathToRfiles = '\" + self.pathToRfiles + \"'\"\n",
      "        \n",
      "        self.PARrdvDirectory = self.variables ['PAR.rdv.directory']\n",
      "        print \"\\nPARrdvDirectory = '\" + self.PARrdvDirectory + \"'\"\n",
      "        \n",
      "#        self.PARinputDirectoryFromYaml = self.inputFiles ['PAR.input.directory']\n",
      "        self.PARinputDirectoryFromYaml = self.qualifiedParams ['PAR.input.directory']\n",
      "        print \"\\nPARinputDirectoryFromYaml = '\" + self.PARinputDirectoryFromYaml + \"'\"\n",
      "\n",
      "            #===================================================================\n",
      "            # \n",
      "            #  NOTE: There is a BUG here in stripping the first two characters \n",
      "            #        off the start of the PARinputDirectoryFromYaml string.\n",
      "            # \n",
      "            #  Not sure why this was done in the R version, but in the test \n",
      "            #  python version where the string is \"inputData\", it reduces that \n",
      "            #  string to \"putData\", which is definitely wrong. \n",
      "            #  Might have been stripping something like \"D/\" off of the \n",
      "            #  R version?\n",
      "            # \n",
      "            #  After having a look at an example tzar log, I can see what's \n",
      "            #  going on now.\n",
      "            #  This code assumes that whatever string is handed to it will need \n",
      "            #  the first two characters removed and then it will splice the rdv \n",
      "            #  directory together with a slash and whatever came after the first \n",
      "            #  two characters. \n",
      "            #  For example, in the example log file this means that you will \n",
      "            #  splice:\n",
      "            # \n",
      "            #      rdv.dir = \"\"\n",
      "            #      dirSlash = \"/\"\n",
      "            # \n",
      "            #  \"./projects/guppy/input_data\" minus the two lead characters \n",
      "            #  to give: \n",
      "            #      \"projects/guppy/input_data\"\n",
      "            # \n",
      "            #  The result is then:\n",
      "            # \n",
      "            #      \"\" + \"/\" + \"projects/guppy/input_data\" = \n",
      "            #      \"/projects/guppy/input_data\"\n",
      "            # \n",
      "            #  So, it looks like this is all setting up to tack this onto \n",
      "            #  the end of another directory path that lacks a trailing slash - \n",
      "            #  though I think that you can actually splice \"x/\" + \"./project\" \n",
      "            #  to get \"x/./project\" and it will still work as a legal path. \n",
      "            #\n",
      "            #  The main problem here is that the yaml file doesn't guarantee \n",
      "            #  anything at all about what variables ['PAR.input.directory'] \n",
      "            #  looks like. That will have to be dealt with here.\n",
      "            # \n",
      "            #  Still, it worked before so for the moment, I'm just going to \n",
      "            #  flag the lead character condition as a WARNING. Should probably \n",
      "            #  throw some kind of exception...\n",
      "            # \n",
      "            #  This is all partly related to whatever tzar does in building \n",
      "            #  the 3 dictionaries that I'm reading in directly here, but tzar \n",
      "            #  modifies.\n",
      "            # \n",
      "            #===================================================================\n",
      "        \n",
      "        leadChars = self.PARinputDirectoryFromYaml [0:2]\n",
      "        print \"\\nleadChars = '\" + leadChars + \"'\"\n",
      "        if leadChars == \"./\":\n",
      "            self.PARinputDirectory = self.PARrdvDirectory + self.constants ['dirSlash'] + self.PARinputDirectoryFromYaml [2:]\n",
      "        else:\n",
      "            self.PARinputDirectory = self.PARrdvDirectory + self.constants ['dirSlash'] + self.PARinputDirectoryFromYaml\n",
      "            print \"\\n***********  WARNING  ***********\\n\" + \"    leadChars of PARinputDirectoryFromYaml = '\" + leadChars + \"' rather than './' so not stripping.\"\n",
      "            print \"    PARinputDirectory may be messed up.\" + \"\\n***********           ***********\"\n",
      "        print \"\\nPARinputDirectory = '\" + self.PARinputDirectory + \"'\"        \n",
      "        \n",
      "    def pprintParamValues (self):\n",
      "        print \"\\n\\nconstants =\"\n",
      "        pprint (self.constants)\n",
      "        print \"\\n\\nvariables =\"\n",
      "        pprint (self.variables)\n",
      "        print \"\\n\\nqualifiedParams =\"\n",
      "        pprint (self.qualifiedParams)\n",
      "        print \"\\n\\nrunParams =\"\n",
      "        pprint (self.runParams)\n",
      "        print \"\\n\\ncurDir =\" + self.curDir + \"\\n\\n\"\n",
      "      \n",
      "#===============================================================================\n",
      "\n",
      "#  Uncomment \"name=main\" line and indent following lines when all of this  \n",
      "#  becomes a full, standalone python file.\n",
      "#  For now, just want the code below to run automatically on every test \n",
      "#  in ipython.\n",
      "        \n",
      "#if __name__ == '__main__':    \n",
      "\n",
      "    #  Move to the guppy working directory.\n",
      "    #  NOTE:  This may be an issue in the long run when running under tzar.\n",
      "    #         I need to move there now so that netpbmfile will be found when imported.\n",
      "    #         However, when running under tzar, we will have cd-ed to the tzar directory.\n",
      "    #         Or will we?  Not sure if that move will show up inside this python code...\n",
      "guppyDir = '/Users/Bill/D/rdv-framework/projects/guppy/'\n",
      "os.chdir (guppyDir)\n",
      "print \"\\nMoved to directory: \" + os.getcwd()\n",
      "\n",
      "oldStyleTest = False\n",
      "if oldStyleTest:\n",
      "    yamlFile = open(\"projectparams.yaml\", \"r\")\n",
      "    \n",
      "    projectParams = yaml.load(yamlFile)\n",
      "    baseParams = projectParams ['base_params']\n",
      "    variables = baseParams ['variables']\n",
      "    outputFiles = baseParams ['output_files']\n",
      "    inputFiles = baseParams ['input_files']\n",
      "\n",
      "    '''\n",
      "    print \"\\n===============================\\n\"\n",
      "    print \"PROJECTPARAMS = \\n\"\n",
      "    pprint (projectParams)\n",
      "    \n",
      "    print \"\\n===============================\\n\"\n",
      "    print \"BASEPARAMS = \\n\"\n",
      "    pprint (baseParams)\n",
      "    '''\n",
      "\n",
      "    if verbose:\n",
      "        print \"\\n===============================\\n\"\n",
      "        print \"INPUTFILES = \\n\"\n",
      "        pprint (inputFiles)\n",
      "        \n",
      "        print \"\\n===============================\\n\"\n",
      "        print \"OUTPUTFILES = \\n\"\n",
      "        pprint (outputFiles)\n",
      "    \n",
      "\n",
      "else:\n",
      "    pickleFileName = '/Users/Bill/D/rdv-framework/projects/guppy/pickeledGuppyInitializationTestParams.pkl'\n",
      "    pkl_file = open (pickleFileName, 'rb')\n",
      "    qualifiedparams = pickle.load (pkl_file)\n",
      "    variables = pickle.load (pkl_file)\n",
      "    pkl_file.close ()\n",
      "\n",
      "    if verbose:\n",
      "        print \"\\n===============================\\n\"\n",
      "        print \"qualifiedparams = \\n\"\n",
      "        pprint (qualifiedparams)\n",
      "        \n",
      "        print \"\\n===============================\\n\"\n",
      "        print \"variables = \\n\"\n",
      "        pprint (variables)\n",
      "        \n",
      "        print \"\\n===============================\\n\"\n",
      "    \n",
      "g = Guppy (None, variables, qualifiedparams)\n",
      "print (\"\\nCreated a Guppy.\\n\")\n",
      "\n",
      "if (verbose):\n",
      "    print (\"-----------------------------\\n\\nINITIALIZED PARAMS:\")\n",
      "    g.pprintParamValues()\n",
      "    \n",
      "    \n",
      "#==============================================================================="
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "\n",
        "====>>>  tempDontMakeDirsYet =  True \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Moved to directory: /Users/Bill/D/rdv-framework/projects/guppy\n",
        "\n",
        "random.seed = '19', class (randomSeed) = 'int\n",
        "\n",
        "PARnumProcessors = 1\n",
        "\n",
        "startingDir = '/Users/Bill/D/rdv-framework/projects/guppy'\n",
        "\n",
        "pathToRfiles = './projects/guppy/'\n",
        "\n",
        "PARrdvDirectory = ''\n",
        "\n",
        "PARinputDirectoryFromYaml = './projects/guppy/input_data/input_data'\n",
        "\n",
        "leadChars = './'\n",
        "\n",
        "PARinputDirectory = '/projects/guppy/input_data/input_data'\n",
        "\n",
        "Created a Guppy.\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PARcurrentRunDirectory = outputFiles ['PAR.current.run.directory']\n",
      "print \"\\nPARcurrentRunDirectory = '\" + PARcurrentRunDirectory + \"'\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "PARcurrentRunDirectory = ''\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#probDistLayersDir = \"./MaxentProbDistLayers/\"    #7/17#  what we want maxent to generate, i.e., the true layers?\n",
      "#PARprobDistLayersDirName = \"MaxentProbDistLayers\"\n",
      "##probDistLayersDir = paste (PARcurrentRunDirectory, \"/\",\n",
      "##                              PARprobDistLayersDirName, \"/\"\n",
      "\n",
      "probDistLayersDir = outputFiles ['PAR.prob.dist.layers.dir.name']\n",
      "probDistLayersDirWithSlash = probDistLayersDir + \"/\"\n",
      "\n",
      "print \"\\nprobDistLayersDir = '\" + probDistLayersDir + \"'\"\n",
      "createDirIfDoesntExist (probDistLayersDir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "probDistLayersDir = 'MaxentProbDistLayers'\n",
        "\n",
        "====>>>  Would make dir 'MaxentProbDistLayers' now.\n"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PARmaxentOutputDirName = \"MaxentOutputs\"\n",
      "\n",
      "maxentOutputDir = outputFiles ['PAR.maxent.output.dir.name']\n",
      "maxentOutputDirWithSlash = maxentOutputDir + dirSlash\n",
      "\n",
      "print \"\\nmaxentOutputDir = '\" + maxentOutputDir + \"'\"\n",
      "createDirIfDoesntExist (maxentOutputDir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "maxentOutputDir = 'MaxentOutputs'\n",
        "\n",
        "====>>>  Would make dir 'MaxentOutputs' now.\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#PARmaxentGenOutputDirName = \"MaxentGenOutputs\"\n",
      "\n",
      "maxentGenOutputDir = outputFiles ['PAR.maxent.gen.output.dir.name']\n",
      "maxentGenOutputDirWithSlash = maxentGenOutputDir + \"/\"\n",
      "\n",
      "print \"\\nmaxentGenOutputDir = '\" + maxentGenOutputDir + \"'\"\n",
      "createDirIfDoesntExist (maxentGenOutputDir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "maxentGenOutputDir = 'MaxentGenOutputs'\n",
        "\n",
        "====>>>  Would make dir 'MaxentGenOutputs' now.\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#analysisDir = \"./ResultsAnalysis/\"\n",
      "#PARanalysisDirName = \"ResultsAnalysis\"\n",
      "\n",
      "analysisDirWithSlash = PARcurrentRunDirectory +  dirSlash + variables ['PAR.analysis.dir.name'] + dirSlash\n",
      "print \"\\nanalysisDirWithSlash = '\" + analysisDirWithSlash + \"'\"\n",
      "createDirIfDoesntExist (analysisDirWithSlash)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "analysisDirWithSlash = '/ResultsAnalysis/'\n",
        "\n",
        "====>>>  Would make dir '/ResultsAnalysis/' now.\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    #  NOTE:  DOES THIS output directory move below NEED TO BE DONE NOW?\n",
      "    #         IE, ARE ALL THE DIRECTORY CREATIONS BELOW ABSOLUTE OR ARE THEY\n",
      "    #         RELATIVE TO BEING IN THE CURRENTRUNDIRECTORY?\n",
      "    #\n",
      "    #         It makes testing all this in python easier if I can separate\n",
      "    #         the moving to a directory from the creation of directories.\n",
      "    \n",
      "    #  IN GENERAL, IT SEEMS LIKE I NEED TO MAKE SURE THAT PATHS ARE ALWAYS BUILT WITH AS LITTLE \n",
      "    #  DEPENDENCE AS POSSIBLE ON WHAT DIRECTORY YOU HAPPEN TO BE SITTING IN AT A GIVEN TIME.  \n",
      "    #  THAT WILL MAKE IT MUCH EASIER TO TEST.  OR WILL IT?  MAYBE A RELATIVE PATH IS A BETTER \n",
      "    #  THING SO THAT YOU CAN CREATE A DUMMY LITTLE TEST AREA AND WORK THERE WITHOUT HURTING \n",
      "    #  ANYTHING ELSE...\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "    #  Move to the output directory.\n",
      "\n",
      "if tempDontMakeDirsYet:\n",
      "    print \"\\n====>>>  Would move to dir '\", PARcurrentRunDirectory, \"' now.\"\n",
      "else:\n",
      "        #  Move to the output directory, e.g.,\n",
      "        #  \"/Users/Bill/tzar/outputdata/Guppy/default_runset/114_Scen_1.inprogress/\"\n",
      "    os.chdir (PARcurrentRunDirectory)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "====>>>  Would move to dir '  ' now.\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##if (!file.exists (\"MaxentOutputs\"))\n",
      "##\t{\n",
      "##\tdir.create (\"MaxentOutputs\")\n",
      "##\t}\n",
      "\n",
      "curFullMaxentEnvLayersDirName = \\\n",
      "    PARcurrentRunDirectory + variables ['PAR.maxent.env.layers.base.name']\n",
      "\n",
      "print \"\\n\\ncurFullMaxentEnvLayersDirName = '\" + curFullMaxentEnvLayersDirName + \"'\"\n",
      "\n",
      "createDirIfDoesntExist (curFullMaxentEnvLayersDirName)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "curFullMaxentEnvLayersDirName = 'MaxentEnvLayers'\n",
        "\n",
        "====>>>  Would make dir 'MaxentEnvLayers' now.\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##if (not file.exists (\"MaxentSamples\"))\n",
      "##\t{\n",
      "##\tdir.create (\"MaxentSamples\")\n",
      "##\t}\n",
      "\n",
      "curFullMaxentSamplesDirName = \\\n",
      "\tPARcurrentRunDirectory + variables ['PAR.maxent.samples.base.name']\n",
      "\n",
      "print \"\\n\\ncurFullMaxentSamplesDirName = '\" + curFullMaxentSamplesDirName + \"'\"\n",
      "\n",
      "createDirIfDoesntExist (curFullMaxentSamplesDirName)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "curFullMaxentSamplesDirName = 'MaxentSamples'\n",
        "\n",
        "====>>>  Would make dir 'MaxentSamples' now.\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#       write.to.file : TRUE,\n",
      "writeToFile = variables ['PAR.write.to.file']\n",
      "\n",
      "#   \t  use.draw.image : FALSE,\n",
      "useDrawImage = variables ['PAR.use.draw.image']\n",
      "\n",
      "#   \t  use.filled.contour : TRUE,\n",
      "useFilledContour = variables ['PAR.use.filled.contour']\n",
      "\n",
      "            #  BEWARE: if this is FALSE, the get.env.layers() routine in\n",
      "            #          guppy.maxent.functions.v6.R does something vestigial\n",
      "            #          that you may not expect (or want) at all !\n",
      "            #          Need to fix that.\n",
      "            #          BTL - 2011.09.20\n",
      "            #  BTL - 2011.10.03 - Is this note even relevant anymore?\n",
      "            #                     Looks like this variable isn't even used now.\n",
      "#   \t  use.pnm.env.layers : TRUE ,\n",
      "usePnmEnvLayers = variables ['PAR.use.pnm.env.layers']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combinedSppTruePresencesTable = None\t\t#  correct Null for PYTHON ???\n",
      "combinedSppSampledPresencesTable = None"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PARnumSppToCreate = variables ['PAR.num.spp.to.create']\n",
      "ARnumSppInReserveSelection = variables ['PAR.num.spp.in.reserve.selection']\n",
      "PARuseOldMaxentOutputForInput = variables ['PAR.use.old.maxent.output.for.input']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PARuseAllSamples = variables ['PAR.use.all.samples']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "CONSTproductRule = variables ['CONST.product.rule']\n",
      "CONSTaddRule = variables ['CONST.add.rule']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "combinedPresSamplesFileName = curFullMaxentSamplesDirName + dirSlash + \\\n",
      "\t\t\t\t\t\t'spp.sampledPres.combined.csv'\n",
      "print \"\\n\\ncombinedPresSamplesFileName = '\" + combinedPresSamplesFileName + \"'\\n\\n\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "combinedPresSamplesFileName = 'MaxentSamples/spp.sampledPres.combined.csv'\n",
        "\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "PARpathToMaxent = variables ['PAR.path.to.maxent']\n",
      "print \"\\n\\nPARpathToMaxent = '\" + PARpathToMaxent + \"'\"\n",
      "\n",
      "maxentFullPathName = startingDir + dirSlash + PARpathToMaxent + dirSlash + 'maxent.jar'\n",
      "\n",
      "print \"\\n\\nmaxentFullPathName = '\" + maxentFullPathName, \"'\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\n",
        "PARpathToMaxent = 'lib/maxent'\n",
        "\n",
        "\n",
        "maxentFullPathName = '/Users/Bill/D/rdv-framework/projects/guppy/lib/maxent/maxent.jar '\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  Look at this ipython notebook under the Subplots heading to see the\n",
      "#  matplotlib way to do this.\n",
      "#      http://nbviewer.ipython.org/urls/raw.github.com/swcarpentry/notebooks/master/matplotlib.ipynb\n",
      "\n",
      "#####    par (mfrow=c(2,2))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "---\n",
      "\n",
      "---\n",
      "\n",
      "---"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Following code is pulled from netpbm.py file to get some examples of declaring a class etc.  Will delete this stuff after I've figured all that out."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#  Code example bits from netpbm.py\n",
      "__version__ = '2013.01.18'\n",
      "#__docformat__ = 'restructuredtext en'\n",
      "#__all__ = ['imread', 'imsave', 'NetpbmFile']\n",
      "\n",
      "\n",
      "def imread(filename, *args, **kwargs):\n",
      "    \"\"\"Return image data from Netpbm file as numpy array.\n",
      "\n",
      "    `args` and `kwargs` are arguments to NetpbmFile.asarray().\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> image = imread('_tmp.pgm')\n",
      "\n",
      "    \"\"\"\n",
      "    try:\n",
      "        netpbm = NetpbmFile(filename)\n",
      "        image = netpbm.asarray()\n",
      "    finally:\n",
      "        netpbm.close()\n",
      "    return image\n",
      "\n",
      "\n",
      "def imsave(filename, data, maxval=None, pam=False):\n",
      "    \"\"\"Write image data to Netpbm file.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> image = numpy.array([[0, 1],[65534, 65535]], dtype=numpy.uint16)\n",
      "    >>> imsave('_tmp.pgm', image)\n",
      "\n",
      "    \"\"\"\n",
      "    try:\n",
      "        netpbm = NetpbmFile(data, maxval=maxval)\n",
      "        netpbm.write(filename, pam=pam)\n",
      "    finally:\n",
      "        netpbm.close()\n",
      "\n",
      "\n",
      "class NetpbmFile(object):\n",
      "    \"\"\"Read and write Netpbm PAM, PBM, PGM, PPM, files.\"\"\"\n",
      "\n",
      "    _types = {b'P1': b'BLACKANDWHITE', b'P2': b'GRAYSCALE', b'P3': b'RGB',\n",
      "              b'P4': b'BLACKANDWHITE', b'P5': b'GRAYSCALE', b'P6': b'RGB',\n",
      "              b'P7 332': b'RGB', b'P7': b'RGB_ALPHA'}\n",
      "\n",
      "    def __init__(self, arg=None, **kwargs):\n",
      "        \"\"\"Initialize instance from filename, open file, or numpy array.\"\"\"\n",
      "        for attr in ('header', 'magicnum', 'width', 'height', 'maxval',\n",
      "                     'depth', 'tupltypes', '_filename', '_fh', '_data'):\n",
      "            setattr(self, attr, None)\n",
      "        if arg is None:\n",
      "            self._fromdata([], **kwargs)\n",
      "        elif isinstance(arg, basestring):\n",
      "            self._fh = open(arg, 'rb')\n",
      "            self._filename = arg\n",
      "            self._fromfile(self._fh, **kwargs)\n",
      "        elif hasattr(arg, 'seek'):\n",
      "            self._fromfile(arg, **kwargs)\n",
      "            self._fh = arg\n",
      "        else:\n",
      "            self._fromdata(arg, **kwargs)\n",
      "\n",
      "    def asarray(self, copy=True, cache=False, **kwargs):\n",
      "        \"\"\"Return image data from file as numpy array.\"\"\"\n",
      "        data = self._data\n",
      "        if data is None:\n",
      "            data = self._read_data(self._fh, **kwargs)\n",
      "            if cache:\n",
      "                self._data = data\n",
      "            else:\n",
      "                return data\n",
      "        return deepcopy(data) if copy else data\n",
      "\n",
      "    def write(self, arg, **kwargs):\n",
      "        \"\"\"Write instance to file.\"\"\"\n",
      "        if hasattr(arg, 'seek'):\n",
      "            self._tofile(arg, **kwargs)\n",
      "        else:\n",
      "            with open(arg, 'wb') as fid:\n",
      "                self._tofile(fid, **kwargs)\n",
      "\n",
      "    def close(self):\n",
      "        \"\"\"Close open file. Future asarray calls might fail.\"\"\"\n",
      "        if self._filename and self._fh:\n",
      "            self._fh.close()\n",
      "            self._fh = None\n",
      "\n",
      "    def __del__(self):\n",
      "        self.close()\n",
      "\n",
      "    def _fromfile(self, fh):\n",
      "        \"\"\"Initialize instance from open file.\"\"\"\n",
      "        fh.seek(0)\n",
      "        data = fh.read(4096)\n",
      "        if (len(data) < 7) or not (b'0' < data[1:2] < b'8'):\n",
      "            raise ValueError(\"Not a Netpbm file:\\n%s\" % data[:32])\n",
      "        try:\n",
      "            self._read_pam_header(data)\n",
      "        except Exception:\n",
      "            try:\n",
      "                self._read_pnm_header(data)\n",
      "            except Exception:\n",
      "                raise ValueError(\"Not a Netpbm file:\\n%s\" % data[:32])\n",
      "\n",
      "    def _read_pam_header(self, data):\n",
      "        \"\"\"Read PAM header and initialize instance.\"\"\"\n",
      "        regroups = re.search(\n",
      "            b\"(^P7[\\n\\r]+(?:(?:[\\n\\r]+)|(?:#.*)|\"\n",
      "            b\"(HEIGHT\\s+\\d+)|(WIDTH\\s+\\d+)|(DEPTH\\s+\\d+)|(MAXVAL\\s+\\d+)|\"\n",
      "            b\"(?:TUPLTYPE\\s+\\w+))*ENDHDR\\n)\", data).groups()\n",
      "        self.header = regroups[0]\n",
      "        self.magicnum = b'P7'\n",
      "        for group in regroups[1:]:\n",
      "            key, value = group.split()\n",
      "            setattr(self, unicode(key).lower(), int(value))\n",
      "        matches = re.findall(b\"(TUPLTYPE\\s+\\w+)\", self.header)\n",
      "        self.tupltypes = [s.split(None, 1)[1] for s in matches]\n",
      "\n",
      "    def _read_pnm_header(self, data):\n",
      "        \"\"\"Read PNM header and initialize instance.\"\"\"\n",
      "        bpm = data[1:2] in b\"14\"\n",
      "        regroups = re.search(b\"\".join((\n",
      "            b\"(^(P[123456]|P7 332)\\s+(?:#.*[\\r\\n])*\",\n",
      "            b\"\\s*(\\d+)\\s+(?:#.*[\\r\\n])*\",\n",
      "            b\"\\s*(\\d+)\\s+(?:#.*[\\r\\n])*\" * (not bpm),\n",
      "            b\"\\s*(\\d+)\\s(?:\\s*#.*[\\r\\n]\\s)*)\")), data).groups() + (1, ) * bpm\n",
      "        self.header = regroups[0]\n",
      "        self.magicnum = regroups[1]\n",
      "        self.width = int(regroups[2])\n",
      "        self.height = int(regroups[3])\n",
      "        self.maxval = int(regroups[4])\n",
      "        self.depth = 3 if self.magicnum in b\"P3P6P7 332\" else 1\n",
      "        self.tupltypes = [self._types[self.magicnum]]\n",
      "\n",
      "    def _read_data(self, fh, byteorder='>'):\n",
      "        \"\"\"Return image data from open file as numpy array.\"\"\"\n",
      "        fh.seek(len(self.header))\n",
      "        data = fh.read()\n",
      "        dtype = 'u1' if self.maxval < 256 else byteorder + 'u2'\n",
      "        depth = 1 if self.magicnum == b\"P7 332\" else self.depth\n",
      "        shape = [-1, self.height, self.width, depth]\n",
      "        size = numpy.prod(shape[1:])\n",
      "        if self.magicnum in b\"P1P2P3\":\n",
      "            data = numpy.array(data.split(None, size)[:size], dtype)\n",
      "            data = data.reshape(shape)\n",
      "        elif self.maxval == 1:\n",
      "            shape[2] = int(math.ceil(self.width / 8))\n",
      "            data = numpy.frombuffer(data, dtype).reshape(shape)\n",
      "            data = numpy.unpackbits(data, axis=-2)[:, :, :self.width, :]\n",
      "        else:\n",
      "            data = numpy.frombuffer(data, dtype)\n",
      "            data = data[:size * (data.size // size)].reshape(shape)\n",
      "        if data.shape[0] < 2:\n",
      "            data = data.reshape(data.shape[1:])\n",
      "        if data.shape[-1] < 2:\n",
      "            data = data.reshape(data.shape[:-1])\n",
      "        if self.magicnum == b\"P7 332\":\n",
      "            rgb332 = numpy.array(list(numpy.ndindex(8, 8, 4)), numpy.uint8)\n",
      "            rgb332 *= [36, 36, 85]\n",
      "            data = numpy.take(rgb332, data, axis=0)\n",
      "        return data\n",
      "\n",
      "    def _fromdata(self, data, maxval=None):\n",
      "        \"\"\"Initialize instance from numpy array.\"\"\"\n",
      "        data = numpy.array(data, ndmin=2, copy=True)\n",
      "        if data.dtype.kind not in \"uib\":\n",
      "            raise ValueError(\"not an integer type: %s\" % data.dtype)\n",
      "        if data.dtype.kind == 'i' and numpy.min(data) < 0:\n",
      "            raise ValueError(\"data out of range: %i\" % numpy.min(data))\n",
      "        if maxval is None:\n",
      "            maxval = numpy.max(data)\n",
      "            maxval = 255 if maxval < 256 else 65535\n",
      "        if maxval < 0 or maxval > 65535:\n",
      "            raise ValueError(\"data out of range: %i\" % maxval)\n",
      "        data = data.astype('u1' if maxval < 256 else '>u2')\n",
      "        self._data = data\n",
      "        if data.ndim > 2 and data.shape[-1] in (3, 4):\n",
      "            self.depth = data.shape[-1]\n",
      "            self.width = data.shape[-2]\n",
      "            self.height = data.shape[-3]\n",
      "            self.magicnum = b'P7' if self.depth == 4 else b'P6'\n",
      "        else:\n",
      "            self.depth = 1\n",
      "            self.width = data.shape[-1]\n",
      "            self.height = data.shape[-2]\n",
      "            self.magicnum = b'P5' if maxval > 1 else b'P4'\n",
      "        self.maxval = maxval\n",
      "        self.tupltypes = [self._types[self.magicnum]]\n",
      "        self.header = self._header()\n",
      "\n",
      "    def _tofile(self, fh, pam=False):\n",
      "        \"\"\"Write Netbm file.\"\"\"\n",
      "        fh.seek(0)\n",
      "        fh.write(self._header(pam))\n",
      "        data = self.asarray(copy=False)\n",
      "        if self.maxval == 1:\n",
      "            data = numpy.packbits(data, axis=-1)\n",
      "        data.tofile(fh)\n",
      "\n",
      "    def _header(self, pam=False):\n",
      "        \"\"\"Return file header as byte string.\"\"\"\n",
      "        if pam or self.magicnum == b'P7':\n",
      "            header = \"\\n\".join((\n",
      "                \"P7\",\n",
      "                \"HEIGHT %i\" % self.height,\n",
      "                \"WIDTH %i\" % self.width,\n",
      "                \"DEPTH %i\" % self.depth,\n",
      "                \"MAXVAL %i\" % self.maxval,\n",
      "                \"\\n\".join(\"TUPLTYPE %s\" % unicode(i) for i in self.tupltypes),\n",
      "                \"ENDHDR\\n\"))\n",
      "        elif self.maxval == 1:\n",
      "            header = \"P4 %i %i\\n\" % (self.width, self.height)\n",
      "        elif self.depth == 1:\n",
      "            header = \"P5 %i %i %i\\n\" % (self.width, self.height, self.maxval)\n",
      "        else:\n",
      "            header = \"P6 %i %i %i\\n\" % (self.width, self.height, self.maxval)\n",
      "        if sys.version_info[0] > 2:\n",
      "            header = bytes(header, 'ascii')\n",
      "        return header\n",
      "\n",
      "    def __str__(self):\n",
      "        \"\"\"Return information about instance.\"\"\"\n",
      "        return unicode(self.header)\n",
      "\n",
      "\n",
      "if sys.version_info[0] > 2:\n",
      "    basestring = str\n",
      "    unicode = lambda x: str(x, 'ascii')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}